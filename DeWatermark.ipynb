{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading EAST text detector...\n",
      "[INFO] text detection took 1.123064 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    " \n",
    "# construct the argument parser and parse the arguments\n",
    "width=320\n",
    "height=320\n",
    "min_confidence=0.5\n",
    "modelpath=\"F:\\\\software\\\\frozen_east_text_detection.pb\"\n",
    "imagepath=\"C:\\\\Users\\\\bbx\\\\new01.png\"\n",
    "# load the input image and grab the image dimensions\n",
    "image = cv2.imread(imagepath)\n",
    "orig = image.copy()\n",
    "(H, W) = image.shape[:2]\n",
    " \n",
    "# set the new width and height and then determine the ratio in change\n",
    "# for both the width and height\n",
    "(newW, newH) = (width,height)\n",
    "rW = W / float(newW)\n",
    "rH = H / float(newH)\n",
    " \n",
    "# resize the image and grab the new image dimensions\n",
    "image = cv2.resize(image, (newW, newH))\n",
    "(H, W) = image.shape[:2]\n",
    " \n",
    "# define the two output layer names for the EAST detector model that\n",
    "# we are interested -- the first is the output probabilities and the\n",
    "# second can be used to derive the bounding box coordinates of text\n",
    "layerNames = [\n",
    "\t\"feature_fusion/Conv_7/Sigmoid\",\n",
    "\t\"feature_fusion/concat_3\"]\n",
    " \n",
    "# load the pre-trained EAST text detector\n",
    "print(\"[INFO] loading EAST text detector...\")\n",
    "net = cv2.dnn.readNet(modelpath)\n",
    " \n",
    "# construct a blob from the image and then perform a forward pass of\n",
    "# the model to obtain the two output layer sets\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "\t(123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "start = time.time()\n",
    "net.setInput(blob)\n",
    "(scores, geometry) = net.forward(layerNames)\n",
    "end = time.time()\n",
    " \n",
    "# show timing information on text prediction\n",
    "print(\"[INFO] text detection took {:.6f} seconds\".format(end - start))\n",
    " \n",
    "# grab the number of rows and columns from the scores volume, then\n",
    "# initialize our set of bounding box rectangles and corresponding\n",
    "# confidence scores\n",
    "(numRows, numCols) = scores.shape[2:4]\n",
    "rects = []\n",
    "confidences = []\n",
    " \n",
    "# loop over the number of rows\n",
    "for y in range(0, numRows):\n",
    "\t# extract the scores (probabilities), followed by the geometrical\n",
    "\t# data used to derive potential bounding box coordinates that\n",
    "\t# surround text\n",
    "\tscoresData = scores[0, 0, y]\n",
    "\txData0 = geometry[0, 0, y]\n",
    "\txData1 = geometry[0, 1, y]\n",
    "\txData2 = geometry[0, 2, y]\n",
    "\txData3 = geometry[0, 3, y]\n",
    "\tanglesData = geometry[0, 4, y]\n",
    " \n",
    "\t# loop over the number of columns\n",
    "\tfor x in range(0, numCols):\n",
    "\t\t# if our score does not have sufficient probability, ignore it\n",
    "\t\tif scoresData[x] < min_confidence:\n",
    "\t\t\tcontinue\n",
    " \n",
    "\t\t# compute the offset factor as our resulting feature maps will\n",
    "\t\t# be 4x smaller than the input image\n",
    "\t\t(offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    " \n",
    "\t\t# extract the rotation angle for the prediction and then\n",
    "\t\t# compute the sin and cosine\n",
    "\t\tangle = anglesData[x]\n",
    "\t\tcos = np.cos(angle)\n",
    "\t\tsin = np.sin(angle)\n",
    " \n",
    "\t\t# use the geometry volume to derive the width and height of\n",
    "\t\t# the bounding box\n",
    "\t\th = xData0[x] + xData2[x]\n",
    "\t\tw = xData1[x] + xData3[x]\n",
    " \n",
    "\t\t# compute both the starting and ending (x, y)-coordinates for\n",
    "\t\t# the text prediction bounding box\n",
    "\t\tendX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "\t\tendY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "\t\tstartX = int(endX - w)\n",
    "\t\tstartY = int(endY - h)\n",
    " \n",
    "\t\t# add the bounding box coordinates and probability score to\n",
    "\t\t# our respective lists\n",
    "\t\trects.append((startX, startY, endX, endY))\n",
    "\t\tconfidences.append(scoresData[x])\n",
    " \n",
    "# apply non-maxima suppression to suppress weak, overlapping bounding\n",
    "# boxes\n",
    "boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    " \n",
    "# loop over the bounding boxes\n",
    "for (startX, startY, endX, endY) in boxes:\n",
    "\t# scale the bounding box coordinates based on the respective\n",
    "\t# ratios\n",
    "\tstartX = int(startX * rW)\n",
    "\tstartY = int(startY * rH)\n",
    "\tendX = int(endX * rW)\n",
    "\tendY = int(endY * rH)\n",
    " \n",
    "\t# draw the bounding box on the image\n",
    "\tcv2.rectangle(orig, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    " \n",
    "# show the output image\n",
    "cv2.imshow(\"Text Detection\", orig)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n"
     ]
    }
   ],
   "source": [
    "##python 图片中查找子图片\n",
    "\n",
    "import aircv as ac\n",
    "import pyautogui\n",
    "\n",
    "def matchImg(imgsrc, imgobj, confidencevalue=0.5):  # imgsrc=原始图像，imgobj=待查找的图片\n",
    "    imsrc = ac.imread(imgsrc)\n",
    "    imobj = ac.imread(imgobj)\n",
    "\n",
    "    match_result = ac.find_template(imsrc, imobj,confidencevalue)  # {'confidence': 0.5435812473297119, 'rectangle': ((394, 384), (394, 416), (450, 384), (450, 416)), 'result': (422.0, 400.0)}\n",
    "    if match_result is not None:\n",
    "        match_result['shape'] = (imsrc.shape[1], imsrc.shape[0])  # 0为高，1为宽\n",
    "\n",
    "    return match_result\n",
    "\n",
    "imgsrc = \"C:\\\\Users\\\\bbx\\\\ggct.png\"\n",
    "imgobj = \"F:\\\\swap\\\\zlq1\\\\0059.jpg\"\n",
    "match_result = matchImg(imgsrc, imgobj)\n",
    "print(match_result[\"rectangle\"][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "#图片修复\n",
    "from PIL import Image\n",
    "from io import BytesIO \n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "path = \"F:\\\\swap\\\\zlq1x\\\\0060.jpg\"\n",
    " \n",
    "img = cv2.imread(path)\n",
    "image = Image.open(path)\n",
    "r, g, b = image.split()     # 将图片分割成 红绿蓝 三个\n",
    "r.show()\n",
    "#g.show()\n",
    "#b.show() \n",
    "\n",
    "hight, width, depth = img.shape[0:3]\n",
    " \n",
    "#图片二值化处理，\n",
    "lower_hsv = np.array([125, 43, 46])  \n",
    "upper_hsv = np.array([155, 255, 255]) \n",
    "thresh = cv2.inRange(img,lower_hsv,upper_hsv)\n",
    " # = cv2.inRange(img, np.array([240, 240, 240]), np.array([255, 255, 255]))\n",
    " \n",
    "#创建形状和尺寸的结构元素\n",
    "#kernel = np.ones((3, 3), np.uint8)\n",
    " \n",
    "#扩张待修复区域\n",
    "#hi_mask = cv2.dilate(thresh, kernel, iterations=1)\n",
    "#specular = cv2.inpaint(img, hi_mask, 5, flags=cv2.INPAINT_TELEA)\n",
    " \n",
    "cv2.namedWindow(\"Image\", 0)\n",
    "cv2.resizeWindow(\"Image\", int(width / 2), int(hight / 2))\n",
    "cv2.imshow(\"Image\", thresh)\n",
    " \n",
    "#cv2.namedWindow(\"newImage\", 0)\n",
    "#cv2.resizeWindow(\"newImage\", int(width / 2), int(hight / 2))\n",
    "#cv2.imshow(\"newImage\", specular)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1942\n",
      "1375\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "images do not match",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8e2e5dc9ca46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mdrop_wartermark\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"F:\\\\swap\\\\zlq1x\\\\0060.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"newDeWM.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-8e2e5dc9ca46>\u001b[0m in \u001b[0;36mdrop_wartermark\u001b[1;34m(path, newpath)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mimgsy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgsy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mpaste\u001b[1;34m(self, im, box, mask)\u001b[0m\n\u001b[0;32m   1525\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0malpha_composite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: images do not match"
     ]
    }
   ],
   "source": [
    "# 必须安装pip install opencv-python 和 pillow\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def drop_wartermark(path, newpath):\n",
    "    img = cv2.imread(path, 1)\n",
    "    # img.shape[:3] 则取彩色图片的高、宽、通道。\n",
    "    hight, width, depth = img.shape[0:3]\n",
    "    print(hight)\n",
    "    print(width)\n",
    "    # 裁剪水印坐标为[y0:y,x0:x1]\n",
    "    cropped = img # [int(hight * 1):hight, int(width * 1):width]\n",
    "    # cropped = img[hight-49:hight, width-180:width]\n",
    "    cv2.imwrite(newpath, cropped)\n",
    "    # 将图片加载为内存对象 参一：完整路径；参二：flag：-1彩色，0灰色，1原有\n",
    "    imgsy = cv2.imread(newpath, 1)\n",
    "    \n",
    "    # 图片二值化处理，把[200,200,200]~[255, 255, 255]以外的颜色变成0\n",
    "    # 这个颜色区间就是水印周边的背景颜色\n",
    "    thresh = cv2.inRange(imgsy, np.array([125, 8, 8]), np.array([155, 25, 25]))\n",
    "    # #创建形状和尺寸的结构元素 创建水印蒙层\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    # 对水印蒙层进行膨胀操作\n",
    "    hi_mask = cv2.dilate(thresh, kernel, iterations=10)\n",
    "    specular = cv2.inpaint(imgsy, hi_mask, 5, flags=cv2.INPAINT_TELEA)\n",
    "    cv2.imshow(\"Image\", specular)\n",
    "    cv2.imwrite(newpath, specular)\n",
    "    \n",
    "    # 覆盖图片\n",
    "    imgsy = Image.open(newpath)\n",
    "    img = Image.open(path)\n",
    "    img.paste(imgsy, (int(width * 0.7), int(hight * 0.9), width, hight))\n",
    "    img.save(newpath)\n",
    "    \n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "drop_wartermark(\"F:\\\\swap\\\\zlq1x\\\\0060.jpg\", \"newDeWM.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###利用openCV+python进行HSV颜色识别，并结合滑动条动态改变目标颜色\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "#定义窗口名称\n",
    "winName='Colors of the rainbow'\n",
    "#定义滑动条回调函数，此处pass用作占位语句保持程序结构的完整性\n",
    "def nothing(x):\n",
    "    pass\n",
    "img_original=cv2.imread('F:\\\\swap\\\\zlq1x\\\\0060.jpg')\n",
    "#颜色空间的转换\n",
    "img_hsv=cv2.cvtColor(img_original,cv2.COLOR_BGR2HSV)\n",
    "#新建窗口\n",
    "cv2.namedWindow(winName)\n",
    "#新建6个滑动条，表示颜色范围的上下边界，这里滑动条的初始化位置即为黄色的颜色范围\n",
    "cv2.createTrackbar('LowerbH',winName,145,255,nothing)\n",
    "cv2.createTrackbar('LowerbS',winName,4,255,nothing)\n",
    "cv2.createTrackbar('LowerbV',winName,178,255,nothing)\n",
    "cv2.createTrackbar('UpperbH',winName,180,255,nothing)\n",
    "cv2.createTrackbar('UpperbS',winName,13,255,nothing)\n",
    "cv2.createTrackbar('UpperbV',winName,241,255,nothing)\n",
    "#while(1):\n",
    "    #函数cv2.getTrackbarPos()范围当前滑块对应的值\n",
    "lowerbH=cv2.getTrackbarPos('LowerbH',winName)\n",
    "lowerbS=cv2.getTrackbarPos('LowerbS',winName)\n",
    "lowerbV=cv2.getTrackbarPos('LowerbV',winName)\n",
    "upperbH=cv2.getTrackbarPos('UpperbH',winName)\n",
    "upperbS=cv2.getTrackbarPos('UpperbS',winName)\n",
    "upperbV=cv2.getTrackbarPos('UpperbV',winName)\n",
    "#得到目标颜色的二值图像，用作cv2.bitwise_and()的掩模\n",
    "img_target=cv2.inRange(img_hsv,(lowerbH,lowerbS,lowerbV),(upperbH,upperbS,upperbV))\n",
    "#cv2.imshow('tar',img_target)\n",
    "\n",
    "mask_not = cv2.bitwise_not(img_target)\n",
    "#cv2.imshow('not',mask_not)\n",
    "\n",
    "im = Image.open('F:\\\\swap\\\\zlq1x\\\\0060.jpg')\n",
    "x,y = im.size \n",
    "p1 = Image.new('RGBA', im.size, (255,255,255))\n",
    "p1.save('tmp.png')\n",
    "img_bg=cv2.imread('tmp.png')\n",
    "\n",
    "dst = cv2.add(img_bg,img_original)\n",
    "#plt.imshow(dst[...,::-1])\n",
    "\n",
    "#输入图像与输入图像在掩模条件下按位与，得到掩模范围内的原图像\n",
    "img_specifiedColor=cv2.bitwise_and(img_bg,img_bg,mask=img_target)\n",
    "cv2.imwrite('temp001.jpg',img_specifiedColor)\n",
    "img2_fg = cv2.imread('temp001.jpg')\n",
    "dst = cv2.add(img_original,img2_fg)\n",
    "\n",
    "cv2.imwrite('060.jpg',dst)\n",
    "#img_specifiedColor=cv2.bitwise_and(img_specifiedColor,img_original,mask=mask_not)\n",
    "cv2.namedWindow(winName, cv2.WINDOW_GUI_EXPANDED)\n",
    "#cv2.resizeWindow(winName,1200, 1900)    \n",
    "cv2.imshow(winName,dst) #img_specifiedColor)\n",
    "#    if cv2.waitKey(1)==ord('q'):\n",
    "#        break\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,3,v. 4,v. 5,v. 6,v. 7,v. 8,v. 9,v. 10,v. 11,v. 12,v. 13,v. 14,v. 15,v. 16,v. 17,v. 18,v. 19,v. 20,21,v. 22,v. 23,v. 24,v. 25,v. 26,v. 27,v. 28,v. 29,v. 30,31,v. 32,v. 33,v. 34,v. 35,v. 36,v. 37,v. 38,v. 39,v. 40,v. 41,v. 42,v. 43,v. 44,v. 45,v. 46,v. 47,v. 48,v. 49,v. 50,51,v. 52,v. 53,v. 54,v. 55,v. 56,v. 57,v. 58,v. 59,v. 60,v. 61,v. 62,v. 63,v. 64,v. 65,v. 66,v. 67,v. 68,v. 69,v. 70,v. 71,v. 72,v. 73,v. 74,v. 75,v. 76,v. 77,v. 78,v. 79,v. 80,81,v. 82,v. 83,v. 84,v. 85,v. 86,v. 87,v. 88,v. 89,v. 90,v. 91,v. 92,v. 93,v. 94,v. 95,v. 96,v. 97,v. 98,v. 99,v. 100,v. 101,v. 102,v. 103,v. 104,v. 105,v. 106,v. 107,v. 108,v. 109,v. 110,v. 111,v. 112,v. 113,v. 114,v. 115,v. 116,v. 117,v. 118,v. 119,v. 120,121,v. 122,v. 123,v. 124,v. 125,v. 126,v. 127,v. 128,v. 129,v. 130,v. 131,v. 132,v. 133,v. 134,v. 135,v. 136,v. 137,v. 138,v. 139,v. 140,v. 141,v. 142,v. 143,v. 144,v. 145,v. 146,v. 147,v. 148,v. 149,v. 150,v. 151,v. 152,v. 153,v. 154,v. 155,v. 156,v. 157,v. 158,v. 159,v. 160,161,v. 162,v. 163,v. 164,v. 165,v. 166,v. 167,v. 168,v. 169,v. 170,v. 171,v. 172,v. 173,v. 174,v. 175,v. 176,v. 177,v. 178,v. 179,v. 180,v. 181,v. 182,v. 183,v. 184,v. 185,v. 186,v. 187,v. 188,v. 189,v. 190,v. 191,v. 192,v. 193,v. 194,v. 195,v. 196,v. 197,v. 198,v. 199,v. 200,201,v. 202,v. 203,v. 204,v. 205,v. 206,v. 207,v. 208,v. 209,v. 210,v. 211,v. 212,v. 213,v. 214,v. 215,v. 216,v. 217,v. 218,v. 219,v. 220,v. 221,v. 222,v. 223,v. 224,v. 225,v. 226,v. 227,v. 228,v. 229,v. 230,v. 231,v. 232,v. 233,v. 234,v. 235,v. 236,v. 237,v. 238,v. 239,v. 240,v. 241,v. 242,v. 243,v. 244,v. 245,v. 246,v. 247,v. 248,v. 249,v. 250,251,v. 252,v. 253,v. 254,v. 255,v. 256,v. "
     ]
    }
   ],
   "source": [
    "logo1=\"\"\"\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃                                                                                                            ┃\n",
    "┃ 去除图片中的广告小方块 1.0         作者 kingboy                                                            ┃\n",
    "┃ PYTHON 得到光标处的句柄,控件标题,控件窗口大小,进程名称及ID                                                 ┃\n",
    "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
    "\n",
    "┌┍┎┏┐┑┒┓└┕┖┗┘┙┚┛┕└┖\n",
    "\"\"\"\n",
    "# 实现查找广告图片并擦除后保存到out目录,20210616\n",
    "\n",
    "from PIL import Image, ImageDraw,ImageFont\n",
    "import aircv as ac\n",
    "import pyautogui\n",
    "w1 = 1\n",
    "h1 = 1\n",
    "def matchImg(imgsrc, imgobj, confidencevalue=0.5):  # imgsrc=原始图像，imgobj=待查找的图片\n",
    "    imsrc = ac.imread(imgsrc)\n",
    "    imobj = ac.imread(imgobj)\n",
    "    global w1,h1\n",
    "    h1 = (imsrc.shape[0])\n",
    "    w1 = (imsrc.shape[1])\n",
    "    match_result = None\n",
    "    if imsrc.shape[0] < imobj.shape[0] and imsrc.shape[1] < imobj.shape[1] :\n",
    "        match_result = ac.find_template(imsrc, imobj,confidencevalue)  # {'confidence': 0.5435812473297119, 'rectangle': ((394, 384), (394, 416), (450, 384), (450, 416)), 'result': (422.0, 400.0)}\n",
    "    if match_result is not None:\n",
    "        match_result['shape'] = (imsrc.shape[1], imsrc.shape[0])  # 0为高，1为宽\n",
    "        print('v',end = '. ')\n",
    "\n",
    "    #print(match_result)\n",
    "    return match_result\n",
    "\n",
    "\n",
    "#h1 = 1 #目标高度\n",
    "#w1 = 1 #目标宽度\n",
    "\n",
    "imgsrc = \"C:\\\\Users\\\\bbx\\\\ggjt.png\"\n",
    "imgsrc2 = \"C:\\\\Users\\\\bbx\\\\ggct.png\"\n",
    "\n",
    "for num in range(2,257):\n",
    "    print(num,end=\",\")#(\"F:\\\\swap\\\\zlq1\\\\out\\\\\"+  \"{0:0>4}\".format(num)  +\".jpg\")\n",
    "    imgobj = \"F:\\\\swap\\\\zlq1x\\\\\"+  \"{0:0>4}\".format(num)  +\".jpg\"\n",
    "\n",
    "    #print(w1,h1)\n",
    "    #print(match_result[\"rectangle\"])\n",
    "    #print(match_result[\"rectangle\"][0][0], match_result[\"rectangle\"][0][1], match_result[\"rectangle\"][1][0], match_result[\"rectangle\"][1][1])\n",
    "\n",
    "    Image1 = Image.open(imgobj)\n",
    "    draw = ImageDraw.Draw(Image1)\n",
    "    #draw.line((20, 20, 150, 150), 'cyan')\n",
    "    \n",
    "    match_result = matchImg(imgsrc, imgobj)\n",
    "    #print(match_result)\n",
    "    if match_result is not None :\n",
    "        draw.rectangle((match_result[\"rectangle\"][0][0], match_result[\"rectangle\"][0][1], match_result[\"rectangle\"][0][0]+w1, match_result[\"rectangle\"][0][1]+h1), 'white', 'white')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    #match_result2 =   matchImg(imgsrc2, imgobj)\n",
    "    #if match_result2 is not None :\n",
    "    #    draw.rectangle((match_result2[\"rectangle\"][0][0], match_result2[\"rectangle\"][0][1], match_result2[\"rectangle\"][0][0]+w1, match_result2[\"rectangle\"][0][1]+h1), 'white', 'white')\n",
    "    #else :\n",
    "    #    pass\n",
    "    \n",
    "    Image1.save(\"F:\\\\swap\\\\zlq1x\\\\out\\\\\"+  \"{0:0>4}\".format(num)  +\".jpg\", \"JPEG\")\n",
    "#draw.rectangle((101, 190, 301, 395), 'yellow', 'black')\n",
    "#draw.arc((100, 200, 300, 400), 0, 180, 'yellow')\n",
    "#draw.ellipse((350, 300, 500, 400), 'yellowgreen', 'wheat')\n",
    "\n",
    "#font = ImageFont.truetype(\"consola.ttf\", 40, encoding=\"unic\")#设置字\n",
    "#draw.text((100, 50), u'Hello World', 'fuchsia', font)\n",
    "\n",
    "#draw.line((0,0) +Image1.size, fill=128)\n",
    "#Image1.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"{0:0>4}\".format(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256,"
     ]
    }
   ],
   "source": [
    "logo1=\"\"\"\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃                                                                                                            ┃\n",
    "┃ 去除黑白文字下面的粉色水印 1.0     作者 kingboy                                                            ┃\n",
    "┃ PYTHON 得到光标处的句柄,控件标题,控件窗口大小,进程名称及ID                                                 ┃\n",
    "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
    "\n",
    "┌┍┎┏┐┑┒┓└┕┖┗┘┙┚┛┕└┖\n",
    "\"\"\"\n",
    "#去除黑白文字下面的粉色水印\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#定义滑动条回调函数，此处pass用作占位语句保持程序结构的完整性\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "for num in range(256,257):\n",
    "    pagepath = \"F:\\\\swap\\\\zlq1x\\\\out\\\\\"+  \"{0:0>4}\".format(num)  +\".jpg\"\n",
    "    outpath  =  \"F:\\\\swap\\\\zlq1x\\\\out\\\\out2\\\\\"+  \"{0:0>4}\".format(num)  +\".jpg\"\n",
    "    img_original=cv2.imread(pagepath) #用来作原图用\n",
    "    img_book  = cv2.imread(pagepath)   # 用来作选取蒙板区域用\n",
    "    img_mask  = cv2.imread('bookmask.bmp',-1) #用来作蒙板遮罩\n",
    "    img_white = cv2.imread('bookmask.bmp') #用来作替换的白色\n",
    "\n",
    "    #cv2.imshow('msk',img_mask)\n",
    "    #print(img_book.shape,img_mask.shape)\n",
    "    if num in [2,20,30,50,80,120,160,200,250] :   #应对尺寸不规整的图片,直接忽略复制保存到目的文件夹.\n",
    "        cv2.imwrite(outpath, img_book)\n",
    "        continue\n",
    "    else:    \n",
    "        #pass #单独使用动态调整时使用\n",
    "        img_book = cv2.bitwise_and(img_book,img_book,mask=img_mask) #擦除水印时使用\n",
    "\n",
    "\n",
    "    #print(img_original.shape,img_book.shape)\n",
    "    #颜色空间的转换\n",
    "    img_hsv=cv2.cvtColor(img_book,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "     #需要动态调整时解开此块注释\n",
    "    #新建6个滑动条，表示颜色范围的上下边界，这里滑动条的初始化位置即为黄色的颜色范围\n",
    "    winName=r'通道选择 hsv模式' #定义窗口名称\n",
    "    cv2.namedWindow(winName,0)      #新建窗口\n",
    "    cv2.createTrackbar('LowerbH',winName,135,255,nothing)\n",
    "    cv2.createTrackbar('LowerbS',winName,2,255,nothing)\n",
    "    cv2.createTrackbar('LowerbV',winName,184,255,nothing)\n",
    "    cv2.createTrackbar('UpperbH',winName,173,255,nothing)\n",
    "    cv2.createTrackbar('UpperbS',winName,82,255,nothing)\n",
    "    cv2.createTrackbar('UpperbV',winName,255,255,nothing)\n",
    "    while(1):\n",
    "        #函数cv2.getTrackbarPos()范围当前滑块对应的值\n",
    "        lowerbH=cv2.getTrackbarPos('LowerbH',winName)\n",
    "        lowerbS=cv2.getTrackbarPos('LowerbS',winName)\n",
    "        lowerbV=cv2.getTrackbarPos('LowerbV',winName)\n",
    "        upperbH=cv2.getTrackbarPos('UpperbH',winName)\n",
    "        upperbS=cv2.getTrackbarPos('UpperbS',winName)\n",
    "        upperbV=cv2.getTrackbarPos('UpperbV',winName)\n",
    "        #得到目标颜色的二值图像，用作cv2.bitwise_and()的掩模\n",
    "        img_target = cv2.inRange(img_hsv,(lowerbH,lowerbS,lowerbV),(upperbH,upperbS,upperbV))\n",
    "        #输入图像与输入图像在掩模条件下按位与，得到掩模范围内的原图像\n",
    "        #cv2.imshow('tar',img_target)\n",
    "        img_specifiedColor=cv2.bitwise_and(img_white,img_white,mask=img_target)\n",
    "        #cv2.imshow('demo',img_specifiedColor)\n",
    "        dst = cv2.add(img_original,img_specifiedColor)\n",
    "        cv2.imshow(\"p\"+str(num),dst)\n",
    "        if cv2.waitKey(1)==ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    #需要动态调整时解开以上块注释\n",
    "    \n",
    "\n",
    "    #  动态调整时注释掉以下两行\n",
    "    #img_target = cv2.inRange(img_hsv,(135,2,184),(173,82,255))\n",
    "    #img_specifiedColor=cv2.bitwise_and(img_white,img_white,mask=img_target)\n",
    "\n",
    "    #  动态调整时注释掉以上两行 \n",
    "\n",
    "    dst = cv2.add(img_original,img_specifiedColor)    \n",
    "    cv2.imwrite(outpath, dst)\n",
    "    print(num,end=\",\")\n",
    "    \n",
    "\n",
    "#cv2.imshow('new1',dst)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "#cv2.imwrite(\"bookmask.png\", img_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1942 1361.20 3088 2182.30 3088 2182.50 3088 2182.80 3088 2182.120 3088 2182.160 3076 2174.200 3088 2182.250 3088 2182."
     ]
    }
   ],
   "source": [
    "for num in range(2,257):\n",
    "    pagepath = \"F:\\\\swap\\\\zlq1x\\\\out\\\\\"+  \"{0:0>4}\".format(num)  +\".jpg\"\n",
    "    img1=cv2.imread(pagepath) #用来作原图用\n",
    "    if not (img1.shape[0] == 1942 and img1.shape[1] == 1375) :\n",
    "        #print(img1.shape,end=\"\")\n",
    "        print(num,img1.shape[0],img1.shape[1],end=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_specifiedColor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-370392e26f21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m#  动态调整时注释掉以上两行\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_original\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_specifiedColor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_specifiedColor' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#定义滑动条回调函数，此处pass用作占位语句保持程序结构的完整性\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "for num in range(301,302):\n",
    "    pagepath = \"F:\\\\swap\\\\zlq1x\\\\out\\\\\"+  \"{0:0>4}\".format(num)  +\".jpg\"\n",
    "    outpath  =  \"F:\\\\swap\\\\zlq1x\\\\out\\\\out2\\\\\"+  \"{0:0>4}\".format(num)  +\".jpg\"\n",
    "    img_original=cv2.imread(pagepath) #用来作原图用\n",
    "    img_book  = cv2.imread(pagepath)   # 用来作选取蒙板区域用\n",
    "\n",
    "    #颜色空间的转换\n",
    "    img_hsv=cv2.cvtColor(img_book,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "     #需要动态调整时解开此块注释\n",
    "    #新建6个滑动条，表示颜色范围的上下边界，这里滑动条的初始化位置即为黄色的颜色范围\n",
    "    winName=r'通道选择 hsv模式' #定义窗口名称\n",
    "    cv2.namedWindow(winName,0)      #新建窗口\n",
    "    cv2.createTrackbar('LowerbH',winName,135,255,nothing)\n",
    "    cv2.createTrackbar('LowerbS',winName,2,255,nothing)\n",
    "    cv2.createTrackbar('LowerbV',winName,184,255,nothing)\n",
    "    cv2.createTrackbar('UpperbH',winName,173,255,nothing)\n",
    "    cv2.createTrackbar('UpperbS',winName,82,255,nothing)\n",
    "    cv2.createTrackbar('UpperbV',winName,255,255,nothing)\n",
    "    while(1):\n",
    "        #函数cv2.getTrackbarPos()范围当前滑块对应的值\n",
    "        lowerbH=cv2.getTrackbarPos('LowerbH',winName)\n",
    "        lowerbS=cv2.getTrackbarPos('LowerbS',winName)\n",
    "        lowerbV=cv2.getTrackbarPos('LowerbV',winName)\n",
    "        upperbH=cv2.getTrackbarPos('UpperbH',winName)\n",
    "        upperbS=cv2.getTrackbarPos('UpperbS',winName)\n",
    "        upperbV=cv2.getTrackbarPos('UpperbV',winName)\n",
    "        #得到目标颜色的二值图像，用作cv2.bitwise_and()的掩模\n",
    "        img_target = cv2.inRange(img_hsv,(lowerbH,lowerbS,lowerbV),(upperbH,upperbS,upperbV))\n",
    "        #输入图像与输入图像在掩模条件下按位与，得到掩模范围内的原图像\n",
    "        #cv2.imshow('tar',img_target)\n",
    "        #img_specifiedColor=cv2.bitwise_and(img_white,img_white,mask=img_target)\n",
    "        #cv2.imshow('demo',img_specifiedColor)\n",
    "        #dst = cv2.add(img_original,img_target)\n",
    "        cv2.imshow(\"p\"+str(num),img_target)\n",
    "        if cv2.waitKey(1)==ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    #需要动态调整时解开以上块注释\n",
    "    \n",
    "\n",
    "    #  动态调整时注释掉以下两行\n",
    "    #img_target = cv2.inRange(img_hsv,(135,2,184),(173,82,255))\n",
    "    #img_specifiedColor=cv2.bitwise_and(img_white,img_white,mask=img_target)\n",
    "\n",
    "    #  动态调整时注释掉以上两行 \n",
    "\n",
    "    dst = cv2.add(img_original,img_specifiedColor)    \n",
    "    cv2.imwrite(outpath, dst)\n",
    "    print(num,end=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "3\n",
      "<class 'str'>\n",
      "3\n",
      "True\n",
      "<class 'bytes'>\n",
      "9\n",
      "b'\\xe6\\x88\\x91\\xe7\\x88\\xb1\\xe5\\xa6\\x9e'\n",
      "<class 'bytes'>\n",
      "6\n",
      "b'\\xce\\xd2\\xb0\\xae\\xe6\\xa4'\n",
      "2\n",
      "删除\n",
      "b'\\xe5\\x88\\xa0\\xe9\\x99\\xa4'\n",
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "oath = '我爱妞'\n",
    "print(type(oath))\n",
    "print(len(oath))\n",
    " \n",
    "oath1 = u'我爱妞'\n",
    "print(type(oath1))\n",
    "print(len(oath1))\n",
    " \n",
    "print(oath==oath1)\n",
    " \n",
    " \n",
    "utf8 = oath.encode('utf-8')\n",
    "print(type(utf8))\n",
    "print(len(utf8))\n",
    "print(utf8)\n",
    " \n",
    "gbk = oath.encode('gbk')\n",
    "print(type(gbk))\n",
    "print(len(gbk))\n",
    "print(gbk)\n",
    " \n",
    " \n",
    "out = open('test.txt','w',encoding = 'utf-8')\n",
    " \n",
    "test = u'\\u5220\\u9664'\n",
    "print(len(test))\n",
    "print(test)\n",
    "test1 = test.encode('utf-8')\n",
    "print(test1)\n",
    "print(type(test1))\n",
    " \n",
    "out.write(test)\n",
    "out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "#1,获取区域\n",
    "#2,遮罩"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
